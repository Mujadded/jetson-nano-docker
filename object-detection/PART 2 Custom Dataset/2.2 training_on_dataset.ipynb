{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "JETSON_INTERFACE_PATH = '../../../jetson-inference'\n",
    "JETSON_INTERFACE_SSD_PATH = f'{JETSON_INTERFACE_PATH}/python/training/detection/ssd'\n",
    "DATA_DIR='/nvdli-nano/data/objectdetection/images/custom/'\n",
    "MODEL_DIR='/nvdli-nano/data/objectdetection/model/custom'\n",
    "TEST_DIR=f'{DATA_DIR}/test'\n",
    "DEFAULT_PRETRAINED_MODEL=f'{JETSON_INTERFACE_SSD_PATH}/models/mobilenet-v1-ssd-mp-0_675.pth'\n",
    "DETECTED_DIR = f'{TEST_DIR}/detected' \n",
    "import os\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "    os.makedirs(DETECTED_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.abspath(JETSON_INTERFACE_SSD_PATH))\n",
    "sys.path.append(os.path.abspath(f'{JETSON_INTERFACE_PATH}/build/aarch64/bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "BATCH = 4\n",
    "LR = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DEFAULT_PRETRAINED_MODEL):\n",
    "    os.system(f\"wget --quiet --show-progress --progress=bar:force:noscroll --no-check-certificate https://nvidia.box.com/shared/static/djf5w54rjvpqocsiztzaandq1m3avr7c.pth -O {DEFAULT_PRETRAINED_MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-19 12:55:35 - Using CUDA...\n",
      "2024-02-19 12:55:35 - Namespace(balance_data=False, base_net=None, base_net_lr=0.001, batch_size=4, checkpoint_folder='/nvdli-nano/data/objectdetection/model/custom', dataset_type='voc', datasets=['/nvdli-nano/data/objectdetection/images/custom/'], debug_steps=10, extra_layers_lr=None, freeze_base_net=False, freeze_net=False, gamma=0.1, lr=0.01, mb2_width_mult=1.0, milestones='80,100', momentum=0.9, net='mb1-ssd', num_epochs=10, num_workers=2, pretrained_ssd='../../../jetson-inference/python/training/detection/ssd/models/mobilenet-v1-ssd-mp-0_675.pth', resume=None, scheduler='cosine', t_max=100, use_cuda=True, validation_epochs=1, weight_decay=0.0005)\n",
      "2024-02-19 12:55:35 - Prepare training datasets.\n",
      "2024-02-19 12:55:35 - No labels file, using default VOC classes.\n",
      "2024-02-19 12:55:35 - Stored labels into file /nvdli-nano/data/objectdetection/model/custom/labels.txt.\n",
      "2024-02-19 12:55:35 - Train dataset size: 20\n",
      "2024-02-19 12:55:35 - Prepare Validation datasets.\n",
      "2024-02-19 12:55:35 - No labels file, using default VOC classes.\n",
      "2024-02-19 12:55:35 - Validation dataset size: 4\n",
      "2024-02-19 12:55:35 - Build network.\n",
      "2024-02-19 12:55:35 - Init from pretrained ssd ../../../jetson-inference/python/training/detection/ssd/models/mobilenet-v1-ssd-mp-0_675.pth\n",
      "2024-02-19 12:55:35 - Took 0.18 seconds to load the model.\n",
      "2024-02-19 12:55:55 - Learning rate: 0.01, Base net learning rate: 0.001, Extra Layers learning rate: 0.01.\n",
      "2024-02-19 12:55:55 - Uses CosineAnnealingLR scheduler.\n",
      "2024-02-19 12:55:55 - Start training from epoch 0.\n",
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "2024-02-19 12:56:52 - Epoch: 0, Validation Loss: 11.2084, Validation Regression Loss 2.2650, Validation Classification Loss: 8.9434\n",
      "2024-02-19 12:56:52 - Saved model /nvdli-nano/data/objectdetection/model/custom/mb1-ssd-Epoch-0-Loss-11.208426475524902.pth\n",
      "2024-02-19 12:56:57 - Epoch: 1, Validation Loss: 6.3281, Validation Regression Loss 2.1679, Validation Classification Loss: 4.1602\n",
      "2024-02-19 12:56:58 - Saved model /nvdli-nano/data/objectdetection/model/custom/mb1-ssd-Epoch-1-Loss-6.328088283538818.pth\n",
      "2024-02-19 12:57:02 - Epoch: 2, Validation Loss: 5.1029, Validation Regression Loss 2.8437, Validation Classification Loss: 2.2592\n",
      "2024-02-19 12:57:02 - Saved model /nvdli-nano/data/objectdetection/model/custom/mb1-ssd-Epoch-2-Loss-5.1029052734375.pth\n",
      "2024-02-19 12:57:07 - Epoch: 3, Validation Loss: 5.2214, Validation Regression Loss 2.4974, Validation Classification Loss: 2.7240\n",
      "2024-02-19 12:57:07 - Saved model /nvdli-nano/data/objectdetection/model/custom/mb1-ssd-Epoch-3-Loss-5.221412658691406.pth\n",
      "2024-02-19 12:57:12 - Epoch: 4, Validation Loss: 3.6858, Validation Regression Loss 1.7861, Validation Classification Loss: 1.8997\n",
      "2024-02-19 12:57:12 - Saved model /nvdli-nano/data/objectdetection/model/custom/mb1-ssd-Epoch-4-Loss-3.6857798099517822.pth\n",
      "2024-02-19 12:57:17 - Epoch: 5, Validation Loss: 3.2682, Validation Regression Loss 1.4305, Validation Classification Loss: 1.8377\n",
      "2024-02-19 12:57:17 - Saved model /nvdli-nano/data/objectdetection/model/custom/mb1-ssd-Epoch-5-Loss-3.2682018280029297.pth\n",
      "2024-02-19 12:57:22 - Epoch: 6, Validation Loss: 3.3400, Validation Regression Loss 1.5536, Validation Classification Loss: 1.7864\n",
      "2024-02-19 12:57:22 - Saved model /nvdli-nano/data/objectdetection/model/custom/mb1-ssd-Epoch-6-Loss-3.339991569519043.pth\n",
      "2024-02-19 12:57:27 - Epoch: 7, Validation Loss: 3.1308, Validation Regression Loss 1.2078, Validation Classification Loss: 1.9231\n",
      "2024-02-19 12:57:27 - Saved model /nvdli-nano/data/objectdetection/model/custom/mb1-ssd-Epoch-7-Loss-3.1308422088623047.pth\n",
      "2024-02-19 12:57:32 - Epoch: 8, Validation Loss: 2.4443, Validation Regression Loss 1.0231, Validation Classification Loss: 1.4212\n",
      "2024-02-19 12:57:32 - Saved model /nvdli-nano/data/objectdetection/model/custom/mb1-ssd-Epoch-8-Loss-2.4443118572235107.pth\n",
      "2024-02-19 12:57:37 - Epoch: 9, Validation Loss: 2.5815, Validation Regression Loss 1.1088, Validation Classification Loss: 1.4727\n",
      "2024-02-19 12:57:37 - Saved model /nvdli-nano/data/objectdetection/model/custom/mb1-ssd-Epoch-9-Loss-2.5815107822418213.pth\n",
      "2024-02-19 12:57:37 - Task done, exiting program.\n"
     ]
    }
   ],
   "source": [
    "!python3 {JETSON_INTERFACE_SSD_PATH}/train_ssd.py --dataset-type=voc --data={DATA_DIR} --model-dir={MODEL_DIR} --batch-size={BATCH} --epochs={NUM_EPOCHS} --lr={LR} --pretrained-ssd={DEFAULT_PRETRAINED_MODEL}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n"
     ]
    }
   ],
   "source": [
    "!python3 {JETSON_INTERFACE_SSD_PATH}/onnx_export.py --model-dir={MODEL_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "live_execution_widget created\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f44eb8e1d7cb40ba9d7f2b7e2648482b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00\\â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import jetson.inference\n",
    "import jetson.utils\n",
    "import ipywidgets\n",
    "from jetcam.utils import bgr8_to_jpeg\n",
    "# USB Camera (Logitech C270 webcam)\n",
    "camera = jetson.utils.videoSource(\"/dev/video0\") \n",
    "net = jetson.inference.detectNet(argv=[f'--model={MODEL_DIR}/ssd-mobilenet.onnx', \n",
    "                                       f'--labels={MODEL_DIR}/labels.txt', \n",
    "                                       '--input-blob=input_0', \n",
    "                                       '--output-cvg=scores', \n",
    "                                       '--output-bbox=boxes'], threshold=0.90)\n",
    "\n",
    "state_widget = ipywidgets.ToggleButtons(options=['stop', 'live'], description='state', value='stop')\n",
    "with open(\"./utils/ready.jpeg\", \"rb\") as file:\n",
    "    default_image = file.read()\n",
    "prediction_widget = ipywidgets.Image(format='jpeg', width=300, height=300, value=default_image)\n",
    "\n",
    "def live(state_widget, net, camera, prediction_widget):\n",
    "    global dataset\n",
    "    while state_widget.value == 'live':\n",
    "        image = camera.Capture()\n",
    "        if image is None: # capture timeout\n",
    "            continue\n",
    "        detections = net.Detect(image, overlay='box,labels,conf')\n",
    "        bgr_img = jetson.utils.cudaAllocMapped(width=image.width,\n",
    "                          height=image.height, format='bgr8')\n",
    "        jetson.utils.cudaConvertColor(image, bgr_img)\n",
    "        prediction_widget.value = bgr8_to_jpeg(jetson.utils.cudaToNumpy(bgr_img))\n",
    "            \n",
    "def start_live(change):\n",
    "    if change['new'] == 'live':\n",
    "        execute_thread = threading.Thread(target=live, args=(state_widget, net, camera, prediction_widget))\n",
    "        execute_thread.start()\n",
    "\n",
    "state_widget.observe(start_live, names='value')\n",
    "\n",
    "live_execution_widget = ipywidgets.VBox([\n",
    "    prediction_widget,\n",
    "    state_widget\n",
    "])\n",
    "\n",
    "# display(live_execution_widget)\n",
    "print(\"live_execution_widget created\")\n",
    "from IPython.display import display\n",
    "display(live_execution_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
